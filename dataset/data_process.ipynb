{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import javalang\n",
    "from tqdm import tqdm\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从源文件中，将camel_code, source_code, comments 分离到三个文件中\n",
    "## camel_code是后续网络训练的code输入\n",
    "## source_code处理后得到AST,进而得到sbt序列\n",
    "## comments 是目标真实值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path='./dataset.json'\n",
    "\n",
    "camel_code_path='./camel_code.txt'\n",
    "\n",
    "source_code_path='./source_code.txt'\n",
    "\n",
    "comment_path='./comment.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCode_Nl(a,c,d,e):\n",
    "    # a: 源文件\n",
    "    # c: camel_code\n",
    "    # d: source_code\n",
    "    # e: comment\n",
    "    with open(a,'r',encoding='utf-8') as testdata:\n",
    "        camel_code=open(c,'w+',encoding='utf-8')\n",
    "        source_code=open(d,'w+',encoding='utf-8')\n",
    "        nl=open(e,'w+',encoding='utf-8')\n",
    "        for line in tqdm(testdata.readlines()):\n",
    "            line=json.loads(line)\n",
    "            \n",
    "            \n",
    "            camel_code.write(line['camel_code'])\n",
    "            camel_code.write('\\n')\n",
    "           \n",
    "            tokens=list(javalang.tokenizer.tokenize(line['source_code']))\n",
    "            newsource=\"\"\n",
    "            for tk in tokens:\n",
    "                if tk.__class__.__name__==\"String\" or tk.__class__.__name__==\"Character\":\n",
    "                    newsource=newsource+\" \"+\"STR_\"\n",
    "                elif \"Integer\" in tk.__class__.__name__ or \"FloatingPoint\" in tk.__class__.__name__:\n",
    "                    newsource=newsource+\" \"+\"NUM_\"\n",
    "                elif tk.__class__.__name__==\"Boolean\":\n",
    "                    newsource=newsource+\" \"+\"BOOL_\"\n",
    "                else:\n",
    "                    newsource=newsource+\" \"+tk.value\n",
    "            newsource=newsource.strip()\n",
    "        \n",
    "            source_code.write(newsource)\n",
    "            source_code.write('\\n')\n",
    "            \n",
    "            nl.write(line['nl'])\n",
    "            nl.write('\\n')\n",
    "            \n",
    "        camel_code.close()\n",
    "        source_code.close()\n",
    "        nl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 485812/485812 [02:32<00:00, 3189.09it/s]\n"
     ]
    }
   ],
   "source": [
    "getCode_Nl(dataset_path,camel_code_path,source_code_path,comment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对source_code进行处理，得到AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_path='./ast.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getast(source,target):\n",
    "    with open(source,'r',encoding='utf-8') as sfile:\n",
    "        lines=sfile.readlines()\n",
    "    with open(target,'w+',encoding='utf-8') as tfile:\n",
    "        count=0\n",
    "        ign_count=0\n",
    "        for line in tqdm(lines):\n",
    "            line=line.strip()\n",
    "            \n",
    "            tokens=javalang.tokenizer.tokenize(line)\n",
    "            tokenslist=list(javalang.tokenizer.tokenize(line))\n",
    "            length=len(tokenslist)\n",
    "            \n",
    "            parser=javalang.parser.Parser(tokens)\n",
    "            \n",
    "            try:\n",
    "                tree=parser.parse_member_declaration()\n",
    "                \n",
    "            except(javalang.parser.JavaSyntaxError,IndexError,StopIteration,TypeError):\n",
    "                #print(line)\n",
    "                #pass\n",
    "                count+=1\n",
    "                continue\n",
    "            \n",
    "            flatten=[]\n",
    "            for path,node in tree:\n",
    "                # flatten[0]的type是啥？\n",
    "                flatten.append({'path':path,'node':node})\n",
    "                \n",
    "            # 不符合ast的标志\n",
    "            ign=False\n",
    "            # ast中间存储\n",
    "            outputs=[]\n",
    "            \n",
    "            \n",
    "            # 下面for循环得到子树关系\n",
    "            for i,Node in enumerate(flatten):\n",
    "                d=collections.OrderedDict()\n",
    "                path=Node['path']\n",
    "                node=Node['node']\n",
    "                \n",
    "                children=[]\n",
    "                # for 循环得到树的结构信息\n",
    "                for child in node.children:\n",
    "                    child_path=None\n",
    "                    # 如果child是ast的节点类型\n",
    "                    if isinstance(child,javalang.ast.Node):\n",
    "                        # tuple((node,))代表啥?\n",
    "                        child_path=path+tuple((node,))\n",
    "                        for j in range(i+1,len(flatten)):\n",
    "                            if child_path==flatten[j]['path'] and child==flatten[j]['node']:\n",
    "                                children.append(j)\n",
    "                    # 如果child是list类型，并且不为空\n",
    "                    if isinstance(child,list) and child:\n",
    "                        child_path=path+(node,child)\n",
    "                        for j in range(i+1,len(flatten)):\n",
    "                            if child_path==flatten[j]['path']:\n",
    "                                children.append(j)\n",
    "                d['id']=i\n",
    "                d['type']=str(node.__class__.__name__)\n",
    "                #d['type']=str(node)\n",
    "                #if children:\n",
    "                d['children']=children\n",
    "                value=None\n",
    "                # 下面得到终端节点（叶节点）value信息\n",
    "                if hasattr(node,'name'):\n",
    "                    value=node.name\n",
    "                elif hasattr(node,'value'):\n",
    "                    value=node.value\n",
    "                elif hasattr(node,'position') and node.position:\n",
    "                    for i,token in enumerate(tokenslist):\n",
    "                        if node.position == token.position:\n",
    "                            pos=i+1\n",
    "                            value=str(token.value)\n",
    "                            # a . b ==> a.b\n",
    "                            while(pos<length and tokenslist[pos].value=='.'):\n",
    "                                value=value+'.'+tokenslist[pos+1].value\n",
    "                                # 有必要pos+2吗?有:a . b . c\n",
    "                                pos+=2\n",
    "                            break\n",
    "                elif type(node) is javalang.tree.This or type(node) is javalang.tree.ExplicitConstructorInvocation:\n",
    "                    value='this'\n",
    "                elif type(node) is javalang.tree.BreakStatement:\n",
    "                    value='break'\n",
    "                elif type(node) is javalang.tree.ContinueStatement:\n",
    "                    value='continue'\n",
    "                elif type(node) is javalang.tree.TypeArgument:\n",
    "                    value=str(node.pattern_type)\n",
    "                elif type(node) is javalang.tree.SuperMethodInvocation or type(node) is javalang.tree.SuperMemberReference:\n",
    "                    value='super.'+str(node.member)\n",
    "                elif type(node) is javalang.tree.Statement or type(node) is javalang.tree.BlockStatement or type(node) is javalang.tree.ForControl or type(node) is javalang.tree.ArrayInitializer or type(node) is javalang.tree.SwitchStatementCase:\n",
    "                    value='None'\n",
    "                elif type(node) is javalang.tree.VoidClassReference:\n",
    "                    value='void.class'\n",
    "                elif type(node) is javalang.tree.SuperConstructorInvocation:\n",
    "                    value='super'\n",
    "                    \n",
    "                if value is not None and type(value) is type('str'):\n",
    "                    d['value']=value\n",
    "                # 无子树，也无值。无子树代表是终端节点，终端节点必有值。这种ast树是不正确的\n",
    "                if not children and not value:\n",
    "                    #print(type(node))\n",
    "                    #print(line)\n",
    "                    ign=True\n",
    "                    ign_count+=1\n",
    "                    break\n",
    "                outputs.append(d)\n",
    "            if not ign:\n",
    "                tfile.write(json.dumps(outputs))\n",
    "                tfile.write('\\n')\n",
    "        print(\"语法错误\",count)\n",
    "        print(ign_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 485812/485812 [13:13<00:00, 612.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语法错误 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "getast(source_code_path,ast_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对AST进行遍历，得到SBT序列 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbt_path='./sbt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbt_process(line,r):\n",
    "    sbt=''\n",
    "    #sbt=line[r]['children']\n",
    "    if not line[r]['children'] :#or not hasattr(line[r],'children')\n",
    "        #if not hasattr(line[r],'children'):\n",
    "        #    print(1)\n",
    "        sbt=\" ( \"+line[r]['type']+\" ) \"+line[r]['type']\n",
    "    else:\n",
    "        sbt=\" ( \"+line[r]['type']\n",
    "        for i in line[r]['children']:\n",
    "            sbt=sbt+get_sbt_process(line,i)\n",
    "        sbt=sbt+\" ) \"+line[r]['type']\n",
    "    return sbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsbt(a,b):\n",
    "    with open(a,'r',encoding='utf-8') as ast:\n",
    "        lines=ast.readlines()\n",
    "    with open(b,'w',encoding='utf-8') as sbt:\n",
    "        for line in tqdm(lines):\n",
    "            line=json.loads(line)\n",
    "            #print(type(line))\n",
    "            #for i in range(len(line)):\n",
    "             #   print(line[i])\n",
    "            #print(type(line[0]))\n",
    "            sbtcode=get_sbt_process(line,0)\n",
    "            sbtcode=sbtcode.strip()\n",
    "            sbt.write(sbtcode+'\\n')\n",
    "            #print(sbt)\n",
    "            #print(type(line[0]['children']))\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 485812/485812 [00:22<00:00, 21985.44it/s]\n"
     ]
    }
   ],
   "source": [
    "getsbt(ast_path,sbt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
